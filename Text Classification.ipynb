{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "init_cell": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from termcolor import colored\n",
    "from collections import defaultdict \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import skipthoughts\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import spacy\n",
    "import unidecode\n",
    "from sklearn import preprocessing\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "tok_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    sentence = unidecode.unidecode(sentence.lower())\n",
    "    mytokens = []\n",
    "    sentence_len = len(sentence.split(' '))\n",
    "    \n",
    "    for token in tok_nlp(sentence):\n",
    "        if (\n",
    "            not token.is_stop and \n",
    "            not token.is_punct and\n",
    "#             not token.pos_ == 'PROPN' and \n",
    "            not token.is_space\n",
    "        ):\n",
    "            mytokens.append(token.lemma_.strip())\n",
    "    \n",
    "    return ' '.join(mytokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    sentence = unidecode.unidecode(sentence.lower())\n",
    "    mytokens = []\n",
    "    for token in tok_nlp(sentence):\n",
    "        if (not token.is_punct and not token.is_space):\n",
    "            lemma = token.lemma_\n",
    "            if (lemma == '-PRON-'):\n",
    "                mytokens.append(token.text.strip())\n",
    "            else:\n",
    "                mytokens.append(token.lemma_.strip())\n",
    "    \n",
    "    return ' '.join(mytokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"how are you doing apple?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(preds, labels):\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_true=labels, y_pred=preds ,normalize=False))\n",
    "    print(metrics.classification_report(y_true=labels, y_pred=preds))\n",
    "    \n",
    "def save_model_results(preds):\n",
    "    pd.DataFrame(preds).to_excel(\"temp.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random_State = 45**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Training Phrases.xlsx', sheet_name='Testing of Models', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "df['Text'] = df['Text'].apply(tokenizer)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "test_emails_df = pd.read_excel('Training Phrases.xlsx', sheet_name='Manual Test cases', nrows=23)\n",
    "test_emails_df = test_emails_df.drop(test_emails_df.index[0])\n",
    "test_emails_df.columns = [\"Label\", \"Email\"]\n",
    "test_emails_df['Email'] = test_emails_df['Email'].apply(tokenizer)\n",
    "test_emails_df['Label'] = test_emails_df['Label'].apply(lambda label: '_'.join(label.lower().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "classes = df.Label.unique()\n",
    "print(\"Total classes: \", len(classes))\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reformatting Data to Reduce Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for _, value in df['Label'].items():\n",
    "    if \"assessment\" in value:\n",
    "        new_df = new_df.append({'Label': \"assessment\"}, ignore_index=True)\n",
    "    elif \"interview\" in value:\n",
    "        new_df = new_df.append({'Label': \"interview\"}, ignore_index=True)\n",
    "    elif (\n",
    "        \"job\" in value or \n",
    "        value == \"cv_past_experience\" or\n",
    "        value == \"application_status\" or\n",
    "        value == \"howto_apply\" or\n",
    "        value == \"feedback\" or\n",
    "        value == \"multiple_role\" or\n",
    "        value == \"reinstate_application\"\n",
    "    ):\n",
    "        new_df = new_df.append({'Label': \"job_application\"}, ignore_index=True)\n",
    "    else:\n",
    "        new_df = new_df.append({'Label': \"job_details\"}, ignore_index=True)\n",
    "        \n",
    "new_df.to_excel(\"4 Classes.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Assessment Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for _, value in df['Label'].items():\n",
    "    if \"assessment\" in value:\n",
    "        new_df = new_df.append({'Label': value}, ignore_index=True)\n",
    "    else:\n",
    "        new_df = new_df.append({'Label': \"other\"}, ignore_index=True)\n",
    "        \n",
    "to_write = pd.concat([df['Text'].reset_index(drop=True), new_df['Label'].reset_index(drop=True)], axis=1)\n",
    "to_write.to_excel(\"Assessment Train.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Interview Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for _, value in df['Label'].items():\n",
    "    if \"interview\" in value:\n",
    "        new_df = new_df.append({'Label': value}, ignore_index=True)\n",
    "    else:\n",
    "        new_df = new_df.append({'Label': \"other\"}, ignore_index=True)\n",
    "        \n",
    "to_write = pd.concat([df['Text'].reset_index(drop=True), new_df['Label'].reset_index(drop=True)], axis=1)\n",
    "to_write.to_excel(\"Interview Train.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Job Details Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for _, value in df['Label'].items():\n",
    "    if (\n",
    "        \"job\" in value or \n",
    "        value == \"cv_past_experience\" or\n",
    "        value == \"application_status\" or\n",
    "        value == \"howto_apply\" or\n",
    "        value == \"feedback\" or\n",
    "        value == \"multiple_role\" or\n",
    "        value == \"reinstate_application\"\n",
    "    ):\n",
    "        new_df = new_df.append({'Label': value}, ignore_index=True)\n",
    "    else:\n",
    "        new_df = new_df.append({'Label': \"other\"}, ignore_index=True)\n",
    " \n",
    "to_write = pd.concat([df['Text'].reset_index(drop=True), new_df['Label'].reset_index(drop=True)], axis=1)\n",
    "to_write.to_excel(\"Job Detail Train.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Job Application Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "\n",
    "for _, value in df['Label'].items():\n",
    "    if (\n",
    "        value == \"salary\" or\n",
    "        value == \"work_experience\" or\n",
    "        value == \"age_limit\" or\n",
    "        value == \"special_needs_at_work\" or\n",
    "        value == \"disability\"\n",
    "    ):\n",
    "        new_df = new_df.append({'Label': value}, ignore_index=True)\n",
    "    else:\n",
    "        new_df = new_df.append({'Label': \"other\"}, ignore_index=True)\n",
    "        \n",
    "to_write = pd.concat([df['Text'].reset_index(drop=True), new_df['Label'].reset_index(drop=True)], axis=1)\n",
    "to_write.to_excel(\"Job Application Train.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove salutations from emails\n",
    "1. Random Forests\n",
    "1. Ensure word embeddings are correct\n",
    "1. Test and Train accuracies should be similar to avoid overfitting\n",
    "1. Reduce the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model Output In Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating mapping column\n",
    "a = pd.DataFrame(preds)\n",
    "b = pd.DataFrame(df['Label'])\n",
    "a.columns = ['Label']\n",
    "b = b.reset_index(drop=True)\n",
    "a = a.reset_index(drop=True)\n",
    "\n",
    "(a==b).to_excel(\"temp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(robert_predictions_labels).to_excel(\"preds.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Multi Stage Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Training Phrases - 4 Classes.xlsx', sheet_name='Testing of Models', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "df['Text'] = df['Text'].apply(tokenizer)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "outer_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "outer_pipe.fit(x_train, y_train)\n",
    "predicted = outer_pipe.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=predicted, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "\n",
    "for i in range(0, x_test.shape[0]):\n",
    "    v = x_test.iloc[i]\n",
    "    main_class = outer_pipe.predict([v])\n",
    "    pred = None\n",
    "    \n",
    "    if (main_class == 'job_application'):\n",
    "        pred = job_app_model.predict([v])[0]\n",
    "    \n",
    "    elif (main_class == 'interview'):\n",
    "        pred = interview_model.predict([v])[0]\n",
    "    \n",
    "    elif (main_class == 'job_details'):\n",
    "        pred = job_detail_model.predict([v])[0]\n",
    "    \n",
    "    elif (main_class == 'assessment'):\n",
    "        pred = assessment_model.predict([v])[0]\n",
    "    \n",
    "    if y_test.iloc[i] == pred:\n",
    "        total_correct += 1\n",
    "    else:\n",
    "        print (\"\\nConfused:\", v, \"\\nActual:\", y_test.iloc[i], \"\\nPredicted:\", pred)\n",
    "      \n",
    "print(\"\\nACCURACY: \", total_correct / x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Assessment Train.xlsx', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "assessment_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "assessment_model.fit(x_train, y_train)\n",
    "predicted = assessment_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=predicted, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Interview Train.xlsx', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "interview_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "interview_model.fit(x_train, y_train)\n",
    "predicted = interview_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=predicted, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Job Application Train.xlsx', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "job_app_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "job_app_model.fit(x_train, y_train)\n",
    "predicted = job_app_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=predicted, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Job Detail Train.xlsx', nrows=456)\n",
    "df = df.drop(df.index[0])\n",
    "df = df[df.columns[[1, 2]]]\n",
    "df.columns = [\"Text\", \"Label\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.20)\n",
    "x_test = x_test.sort_index()\n",
    "y_test = y_test.sort_index()\n",
    "\n",
    "job_detail_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "job_detail_model.fit(x_train, y_train)\n",
    "predicted = job_detail_model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=predicted, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier = SVC(C=150, gamma=0.02, probability=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    ('tfid',  TfidfVectorizer(ngram_range=(1, 3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", SVC(C=150, gamma=0.02, probability=True, class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "predicted = pipe.predict_proba(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=pipe.predict(x_test), normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=pipe.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing on Emails\n",
    "\n",
    "1. SVC = 6/21\n",
    "1. roberta-untok = 11/21\n",
    "1. roberta-large = 9/21\n",
    "1. roberta-v4 = 13/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_preds = predictor.predict(test_emails_df['Email'].values)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=test_emails_df['Label'].values, y_pred=email_preds, normalize=False))\n",
    "print(metrics.classification_report(y_true=test_emails_df['Label'].values, y_pred=email_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extensive Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_a = 0\n",
    "total_b = 0\n",
    "\n",
    "total_iters = 10\n",
    "for i in range(0, total_iters):\n",
    "    print(\"\\nIteration: \", i)\n",
    "    df = pd.read_excel('Training Phrases.xlsx', sheet_name='Testing of Models', nrows=456)\n",
    "    df = df.drop(df.index[0])\n",
    "    df = df[df.columns[[1, 2]]]\n",
    "    df.columns = [\"Text\", \"Label\"]\n",
    "    df['Text'] = df['Text'].apply(tokenizer)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[\"Text\"], df[\"Label\"], random_state=i, test_size=0.2)\n",
    "    \n",
    "#     vectorizer = TfidfVectorizer(ngram_range=(1,3)) \n",
    "#     classifier = SVC(C=150, gamma=0.02, probability=True)\n",
    "#     pipe = Pipeline([('vectorizer', vectorizer),\n",
    "#                      ('classifier', classifier)])\n",
    "                     \n",
    "\n",
    "#     pipe.fit(x_train, y_train)\n",
    "    predicted = ensemble.predict(x_test.values)\n",
    "    accuracy_a = metrics.accuracy_score(y_test, predicted)\n",
    "    total_a += accuracy_a\n",
    "    print(\"Accuracy A:\", accuracy_a)\n",
    "    \n",
    "#     vectorizer = TfidfVectorizer(ngram_range=(1,3)) \n",
    "    classifier = SVC(C=150, gamma=0.02, probability=True)\n",
    "    pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"combined_features\", FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\"tfid\", TfidfVectorizer(ngram_range=(1,3))),\n",
    "                    (\"embed\", SpacyVectorTransformer(nlp)),\n",
    "                ]\n",
    "        )),\n",
    "        (\"classifier\", classifier),\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(x_train, y_train)\n",
    "    predicted = pipe.predict(x_test)\n",
    "    \n",
    "    accuracy_b = metrics.accuracy_score(y_test, predicted)\n",
    "    total_b += accuracy_b\n",
    "    print(\"Accuracy B:\", accuracy_b)\n",
    "\n",
    "print(\"\\nAverage Accuracy A:\", total_a/total_iters)\n",
    "print(\"Average Accuracy B:\", total_b/total_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "nlp = spacy.load(\"en_core_web_lg\")  \n",
    "\n",
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [self.nlp(text).vector for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Embeddings Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GloveTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):    \n",
    "        return [len([tok for tok in tok_nlp(doc) if tok.pos_ == u'VERB']) for doc in X]\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    \n",
    "glove_transformer = GloveTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def create_cat_dict(label):\n",
    "    mydict = {}\n",
    "    for class_ in classes:\n",
    "        mydict[class_] = (class_ == label)\n",
    "        \n",
    "    return mydict\n",
    "\n",
    "\n",
    "def get_preds(texts, labels, output=False):\n",
    "    total_correct = 0\n",
    "    wrong_preds = defaultdict(int)\n",
    "    preds = []\n",
    "    \n",
    "    for test_phrase in zip(texts, labels):\n",
    "        phrase = test_phrase[0]\n",
    "        label = [key for (key, value) in test_phrase[1].items() if value == True][0]\n",
    "        pred_cats = nlp(phrase).cats\n",
    "        pred = max(pred_cats, key=pred_cats.get)\n",
    "        preds.append(pred)\n",
    "        \n",
    "        if (label == pred):\n",
    "            total_correct += 1\n",
    "            \n",
    "        else:\n",
    "            wrong_preds[label] += 1\n",
    "            \n",
    "            if (output):\n",
    "                print(\"\\n\", \"-\"*15, \"\\nPhrase:\", phrase)\n",
    "                print(\"Label:\", label)\n",
    "                print(\"Prediction:\", pred)\n",
    "        \n",
    "    return (total_correct, wrong_preds, preds)\n",
    "\n",
    "\n",
    "def load_data(split=0.80, tok=False):\n",
    "    if tok:\n",
    "        df['tuples'] = df.apply(lambda row: (tokenizer(row['Text']), row['Label']), axis=1)\n",
    "    else:\n",
    "        df['tuples'] = df.apply(lambda row: (row['Text'], row['Label']), axis=1)\n",
    "    \n",
    "    train_data = df['tuples'].tolist()\n",
    "#     random.shuffle(train_data)\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [create_cat_dict(y) for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "#     return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "    return (texts, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_texts, train_cats), (dev_texts, dev_cats) = load_data(tok=True)\n",
    "(texts, cats) = load_data(tok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n_iter = 40\n",
    "drop = 0.15\n",
    "architecture = \"simple_cnn\"\n",
    "\n",
    "\n",
    "# for i in range(0,5):\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data_v2()\n",
    "\n",
    "nlp = spacy.blank(\"en\")  \n",
    "textcat = nlp.create_pipe(\n",
    "    \"textcat\", config={\"exclusive_classes\": True, \"architecture\": architecture}\n",
    ")\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "\n",
    "for label in classes:\n",
    "    textcat.add_label(label)\n",
    "\n",
    "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "\n",
    "pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "with nlp.disable_pipes(*other_pipes):  \n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=drop, losses=losses)\n",
    "\n",
    "# Model Results\n",
    "\n",
    "train_total_correct, train_inaccuracies, train_preds = get_preds(train_texts, train_cats)\n",
    "test_total_correct, test_inaccuracies, test_preds = get_preds(dev_texts, dev_cats)\n",
    "\n",
    "total_correct = test_total_correct + train_total_correct\n",
    "total_rows = len(dev_texts) + len(train_texts)\n",
    "\n",
    "print(\"\\n[TEST SET RESULTS]\\n\",\n",
    "      \"   \\nTotal Correct:\", test_total_correct, \n",
    "      \"   \\nTotal Wrong:\", len(dev_texts)-test_total_correct, \n",
    "      \"   \\nTEST-SET ACCURACY: \", test_total_correct/len(dev_texts),\n",
    "      \"   \\nIncorrect Predictions:\\n \", test_inaccuracies\n",
    "     )\n",
    "\n",
    "print(\"\\n[TRAIN SET RESULTS]\\n\",\n",
    "      \"   \\nTotal Correct:\", train_total_correct, \n",
    "      \"   \\nTotal Wrong:\", len(train_texts)-train_total_correct, \n",
    "      \"   \\nTRAIN-SET ACCURACY: \", train_total_correct/len(train_texts),\n",
    "      \"   \\nIncorrect Predictions:\\n \", train_inaccuracies\n",
    "     )\n",
    "\n",
    "print(\"\\n[OVERALL RESULTS]\\n\",\n",
    "      \"   \\nTotal Correct:\", total_correct, \n",
    "      \"   \\nTotal Wrong:\", total_rows-total_correct,\n",
    "      \"   \\nOVERALL ACCURACY: \", total_correct/total_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fast_aug = naw.WordEmbsAug(\n",
    "    model_type='fasttext', model_path='./models/wiki-news-300d-1M.vec',\n",
    "    action=\"substitute\")\n",
    "\n",
    "w2c_aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path='./models/GoogleNews-vectors-negative300.bin',\n",
    "    action=\"substitute\")\n",
    "\n",
    "text = \"What is the process of applying for this job?\"\n",
    "print(\"Original:\", text)\n",
    "print(\"Augmented (fasttext):\", fast_aug.augment(text) )\n",
    "print(\"Augmented (w2v):\", w2c_aug.augment(text) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='distilbert-base-uncased', action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ludwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ludwig.api import LudwigModel\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**model_definition = {'input_features': [{'name': 'Text', 'type': 'text'}], \n",
    "                    'output_features': [{'name': 'Label', 'type': 'category'}]}**\n",
    "                    \n",
    " 56%\n",
    " \n",
    " **model_definition = {'input_features': [{'name': 'Text', 'type': 'text', 'encoder': 'rnn'}], \n",
    "                    'output_features': [{'name': 'Label', 'type': 'category'}],\n",
    "                    'training': {'epochs': 25}}**\n",
    "                    \n",
    " 30%\n",
    " \n",
    " **model_definition = {'input_features': [{'name': 'Text', 'type': 'text', \"dropout\": True}], \n",
    "                    'output_features': [{'name': 'Label', 'type': 'category'}],\n",
    "                    'training': {'epochs': 25}}**\n",
    "                    \n",
    "48%\n",
    "\n",
    "**model_definition = {'input_features': [{'name': 'Text', 'type': 'text', \"dropout\": True}], \n",
    "                    'output_features': [{'name': 'Label', 'type': 'category'}]}**\n",
    "                    \n",
    "51%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train.csv\")\n",
    "data = data.dropna()\n",
    "df['Text'] = df['Text'].apply(tokenizer)\n",
    "\n",
    "data.Label.value_counts()\n",
    "training_dataframe, validation_dataframe = train_test_split(data,\n",
    "                                                      test_size=0.2,  \n",
    "                                                      random_state=42\n",
    "                                                      )\n",
    "validation_dataframe.reset_index(inplace=True)\n",
    "\n",
    "model_definition = {'input_features': [{'name': 'Text', 'type': 'text', \"level\": \"word\", \"dropout\": True}], \n",
    "                    'output_features': [{'name': 'Label', 'type': 'category'}], 'training': {'epochs':50}}\n",
    "\n",
    "model = LudwigModel(model_definition)\n",
    "\n",
    "training_stats = model.train(training_dataframe, logging_level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions_dataframe = model.predict(validation_dataframe)\n",
    "total_correct = 0\n",
    "\n",
    "for i in range(0, validation_dataframe.shape[0]):\n",
    "    \n",
    "    if predictions_dataframe.Label_predictions[i] == validation_dataframe.Label[i]:\n",
    "        total_correct += 1\n",
    "#     else:\n",
    "#         print(\"\\n\\nPhrase: \", validation_dataframe.Text[i])\n",
    "#         print(\"Prediction: \", predictions_dataframe.Label_predictions[i])\n",
    "#         print(\"Label: \", validation_dataframe.Label[i])\n",
    "    \n",
    "print(\"\\n\\nACCURACY: \", total_correct/validation_dataframe.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Train.csv\")\n",
    "data = data.dropna()\n",
    "training_df, validation_df = train_test_split(data, test_size=0.20, random_state=45)\n",
    "\n",
    "def create_file(df, filename):\n",
    "    file = open(filename +'.txt', \"w\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        label = row['Label'].replace(\"_\", \"-\")\n",
    "        text = row['Text'].replace('\\r', '').replace('\\n', '')\n",
    "        text = tokenizer(text)\n",
    "\n",
    "        line = '\\n__label__' + label + ' ' + text\n",
    "        file.write(line)\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "create_file(training_df, 'fasttext-train')\n",
    "create_file(validation_df, 'fasttext-val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"fasttext-train.txt\", autotuneValidationFile='fasttext-val.txt')                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_correct = 0\n",
    "preds = []\n",
    "for index, row in data.iterrows():\n",
    "    text = tokenizer(row['Text'].replace('\\r', '').replace('\\n', ''))\n",
    "    text = row['Text'].replace('\\r', '').replace('\\n', '')\n",
    "    label = row['Label'].replace(\"_\", \"-\")\n",
    "    pred = model.predict(text)[0][0][9:]\n",
    " \n",
    "    \n",
    "    if label == pred:\n",
    "        total_correct += 1\n",
    "#         print(\"\\n\\nPhrase: \", text)\n",
    "#         print(\"Prediction: \", pred)\n",
    "#         print(\"Label: \", label)\n",
    "    \n",
    "#     else:\n",
    "#         print(\"\\n\\nPhrase: \", text)\n",
    "#         print(\"Prediction: \", pred)\n",
    "#         print(\"Label: \", label)\n",
    "\n",
    "    pred = pred.replace('-', '_')\n",
    "    preds.append(pred)\n",
    "        \n",
    "print(\"\\n\\nACCURACY: \", total_correct/data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train.csv\")\n",
    "df = df.dropna()\n",
    "df['Text'] = df['Text'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Vectorize(vec, X_train, X_test):    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "\n",
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = RandomizedSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Precision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (precision_score(y_test, y_pred, average='macro'), \n",
    "                                                                    recall_score(y_test, y_pred, average='macro'), \n",
    "                                                                    f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "models = {\n",
    "    'Model': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Model': { \n",
    "           'n_estimators': [200, 300, 400, 500],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : [4,5,6,7,8],\n",
    "            'criterion' :['gini', 'entropy']\n",
    "       },\n",
    "}\n",
    "\n",
    "# Encode label categories to numbers\n",
    "enc = LabelEncoder()\n",
    "df['Label'] = enc.fit_transform(df['Label'])\n",
    "labels = list(enc.classes_)\n",
    "\n",
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], random_state=45, test_size=0.2)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(ngram_range=(1,3)), X_train, X_test)\n",
    "\n",
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"combined_features__bow__tfidf__use_idf\": [True, False],\n",
    "    \"combined_features__bow__tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"classifier__bootstrap\": [True, False],\n",
    "    \"classifier__class_weight\": [\"balanced\", None],\n",
    "    \"classifier__n_estimators\": [100, 300, 500, 800, 1200],\n",
    "    \"classifier__max_depth\": [5, 8, 15, 25, 30],\n",
    "    \"classifier__min_samples_split\": [2, 5, 10, 15, 100],\n",
    "    \"classifier__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "search = RandomizedSearchCV(pipe, params)\n",
    "search.fit(x_train, y_train)\n",
    "y_pred = search.predict(x_test)\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'models/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_features = 700\n",
    "maxlen = 70\n",
    "embed_size = 300\n",
    "threshold = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keras_tokenizer = text.Tokenizer(num_words=max_features)\n",
    "keras_tokenizer.fit_on_texts(list(x_train) + list(x_test))\n",
    "x_train = keras_tokenizer.texts_to_sequences(x_train)\n",
    "x_test = keras_tokenizer.texts_to_sequences(x_test)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_index = keras_tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class F1Evaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            y_pred = (y_pred > threshold).astype(int)\n",
    "            score = f1_score(self.y_val, y_pred)\n",
    "            print(\"\\n F1 Score - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_sizes = [1,2,3,5]\n",
    "num_filters = 42\n",
    "\n",
    "def get_model():    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "#    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "    \n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), \n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size),\n",
    "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
    "    \n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "        \n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "        \n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 2\n",
    "\n",
    "F1_Score = F1Evaluation(validation_data=(x_test, y_test), interval=1)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 callbacks=[F1_Score], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "MODEL_NAME = 'roberta-large' \n",
    "t = text.Transformer(MODEL_NAME, classes=classes)\n",
    "trn = t.preprocess_train(x_train.values, y_train.values)\n",
    "val = t.preprocess_test(x_test.values, y_test.values)\n",
    "model = t.get_classifier()\n",
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=16)\n",
    "learner.fit_onecycle(5e-5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(x_test.values)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test.values, y_pred=predictions, normalize=False))\n",
    "print(metrics.classification_report(y_true=y_test.values, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "email_preds = predictor.predict(test_emails_df['Email'].values)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=test_emails_df['Label'].values, y_pred=email_preds, normalize=False))\n",
    "print(metrics.classification_report(y_true=test_emails_df['Label'].values, y_pred=email_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = predictor.predict(df['Text'].values)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=df['Label'].values, y_pred=predictions ,normalize=False))\n",
    "print(metrics.classification_report(y_true=df['Label'].values, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictor.save('/content/gdrive/My Drive/roberta-v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.load_predictor('roberta-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_predictions = predictor.predict_proba(x_test.values)\n",
    "robert_predictions_labels = predictor.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(robert_predictions_labels, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "ensemble = EnsembleVoteClassifier(clfs=[pipe, predictor], weights=[1, 1], voting='soft', refit=False)\n",
    "ensemble.fit(x_train, y_train)\n",
    "ensmbl_preds = ensemble.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(ensmbl_preds, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index = 9\n",
    "actual_index = index - 3\n",
    "text = x_test.iloc[actual_index]\n",
    "print(\"Text: \", text)\n",
    "\n",
    "roberta_pred_prob = max(roberta_predictions[actual_index])\n",
    "roberta_pred = le.inverse_transform([np.argmax(roberta_pred_prob)])[0]\n",
    "\n",
    "print(\"\\nRoberta prediction:\", roberta_pred, \"\\nProbability:\", roberta_pred_prob)\n",
    "\n",
    "\n",
    "svm_pred_prob = max(predicted[actual_index])\n",
    "svm_pred = le.inverse_transform([np.argmax(svm_pred_prob)])[0]\n",
    "\n",
    "print(\"\\nSVM prediction:\", svm_pred, \"\\nProbability:\", svm_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Comparing SVM and RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_svm = 0\n",
    "avg_roberta = 0\n",
    "instances = 0\n",
    "\n",
    "dataset = x_train\n",
    "labels = y_train\n",
    "\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    text = dataset.iloc[i]\n",
    "#     print(\"Text: \", text)\n",
    "\n",
    "    roberta_pred_prob_arr = predictor.predict_proba([text])[0] #roberta_predictions[i]\n",
    "    robera_pred_prob = max(roberta_pred_prob_arr)\n",
    "    roberta_pred = le.inverse_transform([np.argmax(roberta_pred_prob_arr)])[0]\n",
    "    avg_roberta += robera_pred_prob\n",
    "    \n",
    "#     print(\"\\nRoberta prediction:\", roberta_pred, \"\\nProbability:\", robera_pred_prob)\n",
    "\n",
    "    svm_pred_prob_arr = pipe.predict_proba([text])[0] # predicted[i]\n",
    "    svm_pred_prob = max(svm_pred_prob_arr)\n",
    "    svm_pred = le.inverse_transform([np.argmax(svm_pred_prob_arr)])[0]\n",
    "    avg_svm += svm_pred_prob\n",
    "\n",
    "#     print(\"\\nSVM prediction:\", svm_pred, \"\\nProbability:\", svm_pred_prob)\n",
    "\n",
    "#     SVM correct, Roberta wrong\n",
    "    if (svm_pred != roberta_pred and labels.iloc[i] == svm_pred):\n",
    "        \n",
    "#     Roberta correct, SVM wrong\n",
    "#     if (svm_pred != roberta_pred and labels.iloc[i] == roberta_pred):\n",
    "\n",
    "#     Both models wrong\n",
    "#     if (svm_pred != labels.iloc[i] and roberta_pred != labels.iloc[i]):\n",
    "        print(\"Text: \", text)\n",
    "        print(\"\\nSVM prediction:\", svm_pred, \"\\nProbability:\", svm_pred_prob)\n",
    "        print(\"\\nRoberta prediction:\", roberta_pred, \"\\nProbability:\", robera_pred_prob)\n",
    "\n",
    "        print(colored('\\nMismatch', 'red', attrs=['bold']))\n",
    "        print(colored('Label: ' + str(labels.iloc[i]), 'green'))\n",
    "#         print(colored('Ensemble: ' + str(ensmbl_preds[i]), 'blue'))\n",
    "        instances += 1\n",
    "        \n",
    "        print(\"--\" * 20)\n",
    "    \n",
    "print(colored(\"\\nAverage prediction accuracy (SVM): \" + str(avg_svm/dataset.shape[0]), 'green', attrs=['bold']))\n",
    "print(colored(\"Average prediction accuracy (Roberta): \" + str(avg_roberta/dataset.shape[0]), 'green', attrs=['bold']))\n",
    "print(colored(\"Total Instances: \" + str(instances), 'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Manually Scaling Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong = 0\n",
    "correct = 0\n",
    "\n",
    "dataset = x_test\n",
    "labels = y_test\n",
    "\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    print(\"--\" * 20)\n",
    "    \n",
    "    label = labels.iloc[i]\n",
    "    text = dataset.iloc[i]\n",
    "    \n",
    "    roberta_pred_prob_arr = predictor.predict_proba([text])[0] \n",
    "    robera_pred_prob = max(roberta_pred_prob_arr)\n",
    "    roberta_pred = le.inverse_transform([np.argmax(roberta_pred_prob_arr)])[0]\n",
    "    roberta_vals = list(roberta_pred_prob_arr)\n",
    "    roberta_vals.append(np.argmax(roberta_pred_prob_arr))\n",
    "    \n",
    "    svm_pred_prob_arr = pipe.predict_proba([text])[0] \n",
    "    svm_pred_prob = max(svm_pred_prob_arr)\n",
    "    svm_pred = le.inverse_transform([np.argmax(svm_pred_prob_arr)])[0]\n",
    "    svm_vals = list(svm_pred_prob_arr)\n",
    "    svm_vals.append(np.argmax(svm_pred_prob_arr))\n",
    "    \n",
    "    pred_row = roberta_vals + svm_vals\n",
    "    lr_pred = lr_out.predict([pred_row])\n",
    "    lr_pred_label = le.inverse_transform([lr_pred])\n",
    "        \n",
    "    if (lr_pred_label != ensmbl_preds[i]):\n",
    "#         print(colored(\"Correct\", \"green\", attrs=['bold']))\n",
    "#         correct += 1\n",
    "#     else:\n",
    "        print(colored('Mismatch', 'red', attrs=['bold']))\n",
    "        wrong += 1\n",
    "        \n",
    "        print(colored('\\nText: ' + text, 'magenta'))\n",
    "        print(colored('Label: ' + label, 'blue'))\n",
    "        print(\"\\nSVM prediction:\", svm_pred, \"\\nProbability:\", svm_pred_prob)\n",
    "        print(\"\\nRoberta prediction:\", roberta_pred, \"\\nProbability:\", robera_pred_prob)\n",
    "        print(\"\\nEnsemble prediction:\", ensmbl_preds[i])\n",
    "        print(\"LR prediction:\", lr_pred_label[0])\n",
    "\n",
    "\n",
    "print(colored(\"\\nTotal Wrong: \" + str(wrong), 'red', attrs=['bold']))\n",
    "print(colored(\"Total Correct: \" + str(correct), 'green', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Preparing dataset for LRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_x_train = []\n",
    "lr_y_train = []\n",
    "\n",
    "dataset = x_train\n",
    "labels = y_train\n",
    "\n",
    "for i in range(0, dataset.shape[0]):\n",
    "    label = labels.iloc[i]\n",
    "    label_num = le.transform([label])[0]\n",
    "    text = dataset.iloc[i]\n",
    "    \n",
    "    roberta_pred_prob_arr = predictor.predict_proba([text])[0] \n",
    "    roberta_pred = np.argmax(roberta_pred_prob_arr)\n",
    "    roberta_vals = list(roberta_pred_prob_arr)\n",
    "    roberta_vals.append(roberta_pred)\n",
    "    \n",
    "    svm_pred_prob_arr = pipe.predict_proba([text])[0]\n",
    "    svm_pred = np.argmax(svm_pred_prob_arr)\n",
    "    svm_vals = list(svm_pred_prob_arr)\n",
    "    svm_vals.append(svm_pred)\n",
    "    \n",
    "    lr_x_train.append(roberta_vals + svm_vals)\n",
    "    lr_y_train.append(label_num)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training LRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_x_train_pd = pd.DataFrame(lr_x_train)\n",
    "lr_y_train_pd = pd.DataFrame(lr_y_train)\n",
    "\n",
    "\n",
    "lr_out = LogisticRegression()\n",
    "lr_out.fit(lr_x_train_pd, lr_y_train_pd)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.56px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
